{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "edd06650f0bb4b91a1f01b2774485b6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3258d8d7075144a18307b3597c15b17f",
              "IPY_MODEL_fb6e65629d454d9595c2fab848a1492f",
              "IPY_MODEL_1dd62ce1e7a340c6a222e2a63d48290f"
            ],
            "layout": "IPY_MODEL_8a0b1d8dd7204ba6a8bc19ada930c76a"
          }
        },
        "3258d8d7075144a18307b3597c15b17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfa08116f8224e7abb711dc7020f5bb4",
            "placeholder": "​",
            "style": "IPY_MODEL_eeebc942394f4233ac0281b9c64d517d",
            "value": "100%"
          }
        },
        "fb6e65629d454d9595c2fab848a1492f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_806eb2bce94443a99466ae4c0fa2549f",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_687ece2cf3af4668b2ab67f05e3f3ad1",
            "value": 22
          }
        },
        "1dd62ce1e7a340c6a222e2a63d48290f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f5bb0c30dca4ed3916e0adbd548c5fd",
            "placeholder": "​",
            "style": "IPY_MODEL_ce54f355f588410287e26e8eeada058b",
            "value": " 22/22 [00:31&lt;00:00,  1.38s/ba]"
          }
        },
        "8a0b1d8dd7204ba6a8bc19ada930c76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfa08116f8224e7abb711dc7020f5bb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeebc942394f4233ac0281b9c64d517d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "806eb2bce94443a99466ae4c0fa2549f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "687ece2cf3af4668b2ab67f05e3f3ad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f5bb0c30dca4ed3916e0adbd548c5fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce54f355f588410287e26e8eeada058b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cbfbfa89c044121b38b4f6b8fa15410": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_907b8f4133644537a554a099d281cdbc",
              "IPY_MODEL_80e982522d864aefb8931418b0f4f824",
              "IPY_MODEL_2eb452144d7f4c4abdde2b96cad11e8a"
            ],
            "layout": "IPY_MODEL_9d1f17aca30941a58007d511232f4944"
          }
        },
        "907b8f4133644537a554a099d281cdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fa9f3a15a5a474bbe2fca591f9cd426",
            "placeholder": "​",
            "style": "IPY_MODEL_56586341965c48ae8387c8007c73cd01",
            "value": "100%"
          }
        },
        "80e982522d864aefb8931418b0f4f824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141154b6623c4f989d8ef49f8e90a032",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_417e8d7bf96048dda29c9d0041545476",
            "value": 22
          }
        },
        "2eb452144d7f4c4abdde2b96cad11e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37cafb9bd4c1411aa3b253fe901c2cb0",
            "placeholder": "​",
            "style": "IPY_MODEL_b068ca62287a460ebd3f5a65ad0952d0",
            "value": " 22/22 [00:31&lt;00:00,  1.41s/ba]"
          }
        },
        "9d1f17aca30941a58007d511232f4944": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa9f3a15a5a474bbe2fca591f9cd426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56586341965c48ae8387c8007c73cd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "141154b6623c4f989d8ef49f8e90a032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "417e8d7bf96048dda29c9d0041545476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37cafb9bd4c1411aa3b253fe901c2cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b068ca62287a460ebd3f5a65ad0952d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konderal333/HGT-2022-EmDomArDon/blob/main/bert2bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models and data"
      ],
      "metadata": {
        "id": "l935bl02XlAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf0Ee_SOf0qi",
        "outputId": "6b556a1e-8cb6-46f1-b07f-606b693bd7de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HGT-2022-EmDomArDon' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/konderal333/HGT-2022-EmDomArDon.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "oLsjhiWggpKu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/HGT-2022-EmDomArDon/cikkek_10k_cleanedv1.csv')"
      ],
      "metadata": {
        "id": "gcCdIAFigtO1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().values.any())\n",
        "print(sum(df.duplicated()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_jetG8guxLJ",
        "outputId": "3bc28682-11c4-4438-f2bf-37e17fd8f0fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "F9Wnh0wXvTnK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.apply(lambda x: x.str.strip())\n",
        "df['Textbody'] = df['Textbody'].apply(lambda x: re.sub(r\"(\\.)([A-Z])\", r'\\1 \\2', str(x))) # add missing whitespace between sentences\n",
        "\n",
        "df['Lead'] = df['Title'] + '. ' + df['Headline'] # maybe only headline and drop title?\n",
        "df = df.drop(['Title', 'Headline'],axis=1)\n",
        "df.head()\n",
        "\n",
        "#reindexing the dataframe\n",
        "df.reset_index(inplace=True)\n",
        "df = df.drop(['index'], axis=1)"
      ],
      "metadata": {
        "id": "a_Wq2IDmk9oL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8XZHCm-dgwKA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('SZTAKI-HLT/hubert-base-cc')"
      ],
      "metadata": {
        "id": "rO9me5lwgx9z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert2bert\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5\" -O model_bert2bert.tar.gz && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# model\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd\" -O model.tar.gz && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00e93f8-777a-47fc-f0a0-aa58d1b40f3f",
        "id": "OJp93I3EteNc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-26 14:18:28--  https://docs.google.com/uc?export=download&confirm=t&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.24.113, 74.125.24.138, 74.125.24.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.24.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gec13dubek0hos7drgmdu9hmmlam25ac/1669472250000/03710960119062529382/*/1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5?e=download&uuid=9a0cac21-7248-4ff7-89ad-6cbff68c517b [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-26 14:18:29--  https://doc-0o-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/gec13dubek0hos7drgmdu9hmmlam25ac/1669472250000/03710960119062529382/*/1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5?e=download&uuid=9a0cac21-7248-4ff7-89ad-6cbff68c517b\n",
            "Resolving doc-0o-18-docs.googleusercontent.com (doc-0o-18-docs.googleusercontent.com)... 142.250.4.132, 2404:6800:4003:c06::84\n",
            "Connecting to doc-0o-18-docs.googleusercontent.com (doc-0o-18-docs.googleusercontent.com)|142.250.4.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2648670050 (2.5G) [application/x-gzip]\n",
            "Saving to: ‘model_bert2bert.tar.gz’\n",
            "\n",
            "model_bert2bert.tar 100%[===================>]   2.47G   382MB/s    in 6.8s    \n",
            "\n",
            "2022-11-26 14:18:36 (373 MB/s) - ‘model_bert2bert.tar.gz’ saved [2648670050/2648670050]\n",
            "\n",
            "--2022-11-26 14:18:38--  https://docs.google.com/uc?export=download&confirm=t&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.24.113, 74.125.24.138, 74.125.24.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.24.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tokjgcktabtsvccu4qq4gh6gpeefj2qh/1669472250000/03710960119062529382/*/1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd?e=download&uuid=8ef55c91-6696-4f0c-9c71-fa89e2aec7d6 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-26 14:18:39--  https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/tokjgcktabtsvccu4qq4gh6gpeefj2qh/1669472250000/03710960119062529382/*/1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd?e=download&uuid=8ef55c91-6696-4f0c-9c71-fa89e2aec7d6\n",
            "Resolving doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)... 142.250.4.132, 2404:6800:4003:c06::84\n",
            "Connecting to doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)|142.250.4.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 927224269 (884M) [application/x-gzip]\n",
            "Saving to: ‘model.tar.gz’\n",
            "\n",
            "model.tar.gz        100%[===================>] 884.27M   215MB/s    in 4.1s    \n",
            "\n",
            "2022-11-26 14:18:43 (215 MB/s) - ‘model.tar.gz’ saved [927224269/927224269]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive('model.tar.gz', 'model')\n",
        "shutil.unpack_archive('model_bert2bert.tar.gz', 'bert2bert')"
      ],
      "metadata": {
        "id": "J5A7_9vkteNf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "bert2bert_model_path = '/content/bert2bert/model/pytorch_model.bin'\n",
        "bert2bert_config = '/content/bert2bert/model/config.json'\n",
        "\n",
        "model_path = '/content/model/model/pytorch_model.bin'\n",
        "config = '/content/model/model/config.json'\n",
        "\n",
        "bert2bert = EncoderDecoderModel.from_pretrained(bert2bert_model_path, config=bert2bert_config).to(device)\n",
        "model = EncoderDecoderModel.from_pretrained(model_path, config=config).to(device)"
      ],
      "metadata": {
        "id": "1gftlAZQ-DKl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial notebook:\n",
        "\n",
        "https://colab.research.google.com/drive/1WIk2bxglElfZewOHboPFNj8H44_VAyKE?usp=sharing&fbclid=IwAR2-pdnudSutvgqIlUUg4NP1Q0wJO9NQbteg_wVL9n8gsS2yMTfMp9YfC6w#scrollTo=bYmdx-W1NAky\n",
        "\n",
        "The majority of the codes found in that notebook is outdated, so we needed to make a couple of augmentations and changes in order to make them work in our environment."
      ],
      "metadata": {
        "id": "VvDFzCOSq8hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to handle larger inputs than 512 tokens"
      ],
      "metadata": {
        "id": "yl-We1JlC_bD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "gmJpNVgTDREn",
        "outputId": "66b11377-282a-4fc0-e745-7fb48f22a682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting quntoken\n",
            "  Downloading quntoken-3.1.8-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 7.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: quntoken\n",
            "Successfully installed quntoken-3.1.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_of_tokens = {} \n",
        "#this dict will contain the article title as keys and the tokenized lists from the function below as values\n",
        "\n",
        "def text_to_tokens(art_title, x):      \n",
        "  #insert the text to tokenize; first breaks text into sentences, then makes a list of lists with the i-th element being the tokenization of the i-th sentence\n",
        "  #dictionary is being used for faster computation and easier accessibility\n",
        "  sentence_list = []\n",
        "  token_list = []\n",
        "\n",
        "  x = re.sub(r\"(\\.)([A-Z])\", r'\\1 \\2', x) # fixes missings whitespaces between sentences\n",
        " \n",
        "  for sen in nltk.tokenize.sent_tokenize(x):\n",
        "    sentence_list.append(sen)\n",
        "    token_list.append(tokenizer.tokenize(sen))\n",
        "\n",
        "  dict_of_tokens[art_title] = token_list\n",
        "\n",
        "# making the BERT tokenized sentences from each article\n",
        "for i in range(len(df.Lead)):\n",
        "  text_to_tokens(df.Lead[i].strip(), df.Textbody[i])"
      ],
      "metadata": {
        "id": "Q0tqz2DfDHyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some basic statistics about the number of tokens"
      ],
      "metadata": {
        "id": "Z_jZfSbsDWjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "\n",
        "number_of_tokens_all = []\n",
        "\n",
        "for tokens in dict_of_tokens.values():\n",
        "  length = 0\n",
        "  for lists in tokens:\n",
        "    length += len(lists)\n",
        "  number_of_tokens_all.append(length)\n"
      ],
      "metadata": {
        "id": "yldWq4hgDVkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(number_of_tokens_all, bins=100, density=False)\n",
        "plt.title('Distribution of number of tokens generated from articles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Fj5dC77JDZXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Median of tokens: \", statistics.median(number_of_tokens_all))\n",
        "print(\"Mean of tokens: \", statistics.mean(number_of_tokens_all))"
      ],
      "metadata": {
        "id": "qp1FCUJCDaES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of articles with tokens more that 510:\n",
        "print(np.sum(np.asarray(number_of_tokens_all) > 510))"
      ],
      "metadata": {
        "id": "QbLh648cDcFw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process data"
      ],
      "metadata": {
        "id": "NvtkSH6FXrZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_to_model_inputs(batch):\n",
        "        # Tokenize the input and target data\n",
        "        inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512)\n",
        "        outputs = tokenizer(batch['Lead'], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "        batch['input_ids'] = inputs.input_ids\n",
        "        batch['attention_mask'] = inputs.attention_mask\n",
        "        batch['decoder_input_ids'] = outputs.input_ids\n",
        "        batch['decoder_attention_mask'] = outputs.attention_mask\n",
        "        batch['labels'] = outputs.input_ids.copy()\n",
        "\n",
        "        # batch['labels'] = [[-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        #                    for labels in batch['labels']]\n",
        "        batch['labels'] = [-100 if token == tokenizer.pad_token_id else token for token in batch['labels']]\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "uBAQRVkUeV3d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of articles\n",
        "df.shape[0]"
      ],
      "metadata": {
        "id": "m5Hdl4WlsYKO",
        "outputId": "65a1f076-372e-4bb6-fdcf-7d57642126d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9386"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Data\n",
        "\n",
        "# split is 70-15-15\n",
        "\n",
        "train_data = df.iloc[0:int(np.floor(df.shape[0]*0.7))]\n",
        "val_data = df.iloc[int(np.floor(df.shape[0]*0.7)):int(np.floor(df.shape[0]*0.85))]\n",
        "test_data = df.iloc[int(np.floor(df.shape[0]*0.85)):]\n",
        "\n",
        "\n",
        "#Partial Data\n",
        "#train_data = df.iloc[0:20]\n",
        "#val_data = df.iloc[20:30]\n",
        "#test_data = df.iloc[30:40]\n",
        "\n",
        "#train_data.reset_index(inplace=True)\n",
        "#val_data.reset_index(inplace=True)\n",
        "#test_data.reset_index(inplace=True)\n",
        "\n",
        "#train_data = train_data.drop(['index'], axis=1)\n",
        "#val_data = val_data.drop(['index'], axis=1)\n",
        "#test_data = test_data.drop(['index'], axis=1)"
      ],
      "metadata": {
        "id": "0koyJhZXmQPF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming the train and validation data\n",
        "train_data = train_data.apply(process_data_to_model_inputs, axis=1)\n",
        "train_data = train_data.drop(['Textbody', 'Lead'], axis=1)\n",
        "\n",
        "val_data = val_data.apply(process_data_to_model_inputs, axis=1)\n",
        "val_data = val_data.drop(['Textbody', 'Lead'], axis=1)"
      ],
      "metadata": {
        "id": "vPUFBFq3jXip"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "Voqr9PbmvebJ",
        "outputId": "2398411f-accd-4a03-eee1-08bd51ad97fc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           input_ids  \\\n",
              "0  [2, 2155, 7155, 2524, 4046, 4341, 15269, 14826...   \n",
              "1  [2, 30196, 9688, 11787, 11628, 2005, 11149, 22...   \n",
              "2  [2, 4405, 2546, 8984, 3576, 2079, 2005, 16667,...   \n",
              "3  [2, 22158, 6688, 29536, 2005, 13549, 31735, 12...   \n",
              "4  [2, 10708, 11447, 2685, 2066, 9763, 31736, 200...   \n",
              "\n",
              "                                      attention_mask  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                   decoder_input_ids  \\\n",
              "0  [2, 21086, 2018, 6480, 2045, 26204, 14350, 804...   \n",
              "1  [2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...   \n",
              "2  [2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...   \n",
              "3  [2, 12930, 12887, 6704, 7671, 2837, 20664, 297...   \n",
              "4  [2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...   \n",
              "\n",
              "                              decoder_attention_mask  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                              labels  \n",
              "0  [2, 21086, 2018, 6480, 2045, 26204, 14350, 804...  \n",
              "1  [2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...  \n",
              "2  [2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...  \n",
              "3  [2, 12930, 12887, 6704, 7671, 2837, 20664, 297...  \n",
              "4  [2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d336187-474f-40a1-b3c4-85698a2d47a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>decoder_input_ids</th>\n",
              "      <th>decoder_attention_mask</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 2155, 7155, 2524, 4046, 4341, 15269, 14826...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 21086, 2018, 6480, 2045, 26204, 14350, 804...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 21086, 2018, 6480, 2045, 26204, 14350, 804...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 30196, 9688, 11787, 11628, 2005, 11149, 22...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 4405, 2546, 8984, 3576, 2079, 2005, 16667,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 22158, 6688, 29536, 2005, 13549, 31735, 12...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 12930, 12887, 6704, 7671, 2837, 20664, 297...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 12930, 12887, 6704, 7671, 2837, 20664, 297...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 10708, 11447, 2685, 2066, 9763, 31736, 200...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d336187-474f-40a1-b3c4-85698a2d47a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d336187-474f-40a1-b3c4-85698a2d47a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d336187-474f-40a1-b3c4-85698a2d47a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "i2Ntmb6Bi9bY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to arrow dataset (easier to use)\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "from datasets import Dataset\n",
        "\n",
        "train_data = Dataset(pa.Table.from_pandas(train_data))\n",
        "val_data = Dataset(pa.Table.from_pandas(val_data))\n",
        "test_data = Dataset(pa.Table.from_pandas(test_data))\n",
        "\n",
        "# format type\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz9aXIWvguOJ",
        "outputId": "3d967f15-1330-45a2-b42c-8c94a2853159"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'],\n",
              "    num_rows: 6570\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the train and validation sets to tensors\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "metadata": {
        "id": "AtoQw3txhJye"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "train_data[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz2hUNUaf7Mq",
        "outputId": "078b7b5c-920f-4292-96ba-34e8b96da300"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2, 21086,  2018,  ...,  -100,  -100,  -100],\n",
              "        [    2, 28589,  6997,  ...,  -100,  -100,  -100],\n",
              "        [    2,  5388, 28306,  ...,  -100,  -100,  -100],\n",
              "        ...,\n",
              "        [    2,  2155,  3165,  ...,  -100,  -100,  -100],\n",
              "        [    2,  3512,  2664,  ...,  -100,  -100,  -100],\n",
              "        [    2,  5753,  2336,  ...,  -100,  -100,  -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction and evaluation before training"
      ],
      "metadata": {
        "id": "nE1kDLgVYQn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "!pip install rouge_score\n",
        "import datasets\n",
        "rouge = datasets.load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "34fJFTXTuaHP",
        "outputId": "f9e8d912-9a89-4e86-c786-48e46c4947f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.3.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary generation\n",
        "\n",
        "def generate_summary(batch):\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "    input_ids = inputs.input_ids.to('cuda')\n",
        "    attention_mask = inputs.attention_mask.to('cuda')\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch['pred_summary'] = output_str\n",
        "\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "9-bSOnCrM1Ct"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example article\n",
        "batch = df.iloc[10]\n",
        "batch['Textbody']"
      ],
      "metadata": {
        "id": "dkfyOxW0Q-rG",
        "outputId": "ed24d7a8-1c31-4e95-c7d4-d67d044916e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Találkozni szeretett volna a Kölcsey Ferenc Gimnázium tanárait menesztő tankerületi vezetővel Soproni Tamás, terézvárosi polgármester. Marosi Betrix azonban nem látta indokoltnak, hogy beszélgessenek. A tankerületi vezető levelét Facebook-oldalán tette közzé a Momentum politikusa. Azt írja Marosi, hogy „természetesen a tankerületi központnak is az az érdeke, hogy az iskolában a helyzet normalizálódjon, a pedagógusok tanítsanak, a diákok tanuljanak”. A nevelés-oktatás feltételeinek biztosítása a VI. kerület állami fenntartású iskoláiban a tankerület feladata és felelőssége,„a tankerületi központ sem kíván beleszólni abba, hogy az Önkormányzat hogyan és kikkel látja el a feladatait.”A tankerületi vezető nem látja indokoltnak, hogy személyesen is találkozzon a kerület polgármesterével, mert a munkáltatói intézkedés „kizárólag a hatályos jogszabályokból fakadó lépés volt”. Marosi szerint az érintett pedagógusok a többszöri figyelmeztetés ellenére is visszatérően megszegték „a pedagógus jogviszonyból fakadó kötelezettségeket”.„Természetesen köszönettel veszem Tisztelt Polgármester Úr közreműködését, amennyiben az arra irányul, hogy a pedagógusok a jogszabályokban számukra biztosított, törvényes módon fejezzék ki véleményüket, úgy, hogy az a gyermekek tanuláshoz való jogának érvényesülését ne korlátozza” – fogalmaz a levélben. Soproni azért kezdeményezett beszélgetést, mert aggasztja a kerületi diákok és tanárok sorsa. „Mi tesszük tovább a dolgunkat: százmilliókkal támogatjuk a helyi iskolák felújítását, cserébe csak a tanárok és diákok felé mutatott empatikus hozzáállást várnánk” – írja a Facebook-bejegyzésében. Múlt pénteken a VI. kerületi Kölcsey Ferenc Gimnázium több, a polgári engedetlenségben résztvevő tanárát azonnali hatállyal menesztették. A tankerület azt írta a Telexnek, hogy az érintett tanárok felmentése indokolt, mert a tanárok írásbeli figyelmeztetés után is többször megismételték „jogszerűtlen cselekedetüket”. Még aznap több százan tiltakoztak a döntés ellen a gimnázium előtt, majd a héten tovább folytatódtak a tüntetések. A menesztett tanárok munkaügyi pert indítanak.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the summary\n",
        "inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "input_ids = inputs.input_ids.to('cuda')\n",
        "attention_mask = inputs.attention_mask.to('cuda')\n",
        "outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "output_str[0]"
      ],
      "metadata": {
        "id": "GrqvfI-TRIXK",
        "outputId": "f837aa87-d306-4e3c-f405-583c04044b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Soproni Tamás szerint a tankerületi központnak is az az érdeke, hogy a tanárok és diákok tanuljanak.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original lead\n",
        "df.iloc[10]['Lead']"
      ],
      "metadata": {
        "id": "o_Lq_aLntj6n",
        "outputId": "cc298220-ed02-4929-ef25-51b8998d1277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Lepattintotta a kölcseys tanárokat menesztő tankerületi vezető Soproni Tamást, aki beszélgetésre hívta. Nem akart találkozni a momentumos polgármesterrel, mert ő sem akar beleszólni abba, hogy az önkormányzat hogyan és kikkel látja el a feladatait.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the tokens\n",
        "for t in input_ids:\n",
        "    print(tokenizer.convert_ids_to_tokens(t))"
      ],
      "metadata": {
        "id": "7MuKwvBcBe5I",
        "outputId": "617abe9c-6d1e-498a-f71c-0162ac25b8b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Találkoz', '##ni', 'szeretett', 'volna', 'a', 'Kölcs', '##ey', 'Ferenc', 'Gimnázium', 'tanára', '##it', 'men', '##esztő', 'tank', '##erületi', 'vezető', '##vel', 'Sopron', '##i', 'Tamás', ',', 'ter', '##éz', '##városi', 'polgármester', '.', 'Maros', '##i', 'Bet', '##rix', 'azonban', 'nem', 'látta', 'indokolt', '##nak', ',', 'hogy', 'beszélg', '##essenek', '.', 'A', 'tank', '##erületi', 'vezető', 'level', '##ét', 'Facebook', '-', 'oldalán', 'tette', 'közzé', 'a', 'Mo', '##ment', '##um', 'politikus', '##a', '.', 'Azt', 'írja', 'Maros', '##i', ',', 'hogy', '„', 'természetesen', 'a', 'tank', '##erületi', 'központ', '##nak', 'is', 'az', 'az', 'érdeke', ',', 'hogy', 'az', 'iskolában', 'a', 'helyzet', 'norm', '##alizál', '##ódjon', ',', 'a', 'pedagógusok', 'tanít', '##sanak', ',', 'a', 'diákok', 'tanul', '##janak', '”', '.', 'A', 'nevelés', '-', 'oktatás', 'feltételeinek', 'biztosítása', 'a', 'VI', '.', 'kerület', 'állami', 'fenntart', '##ású', 'iskol', '##áiban', 'a', 'tank', '##erület', 'feladata', 'és', 'felelőssége', ',', '„', 'a', 'tank', '##erületi', 'központ', 'sem', 'kíván', 'beleszól', '##ni', 'abba', ',', 'hogy', 'az', 'Önkormányzat', 'hogyan', 'és', 'kik', '##kel', 'látja', 'el', 'a', 'feladatait', '.', '”', 'A', 'tank', '##erületi', 'vezető', 'nem', 'látja', 'indokolt', '##nak', ',', 'hogy', 'személyesen', 'is', 'találkoz', '##zon', 'a', 'kerület', 'polgármester', '##ével', ',', 'mert', 'a', 'munkáltatói', 'intézkedés', '„', 'kizárólag', 'a', 'hatályos', 'jogszabályok', '##ból', 'fakadó', 'lépés', 'volt', '”', '.', 'Maros', '##i', 'szerint', 'az', 'érintett', 'pedagógusok', 'a', 'többszöri', 'figyelmeztetés', 'ellenére', 'is', 'visszatérő', '##en', 'megszeg', '##ték', '„', 'a', 'pedagógus', 'jogviszony', '##ból', 'fakadó', 'kötelezettségek', '##et', '”', '.', '„', 'Természetesen', 'köszönet', '##tel', 'veszem', 'Tisztelt', 'Polgármester', 'Úr', 'közreműködés', '##ét', ',', 'amennyiben', 'az', 'arra', 'irányul', ',', 'hogy', 'a', 'pedagógusok', 'a', 'jogszabályokban', 'számukra', 'biztosított', ',', 'törvényes', 'módon', 'feje', '##z', '##zék', 'ki', 'vélemény', '##üket', ',', 'úgy', ',', 'hogy', 'az', 'a', 'gyermekek', 'tanulás', '##hoz', 'való', 'jogának', 'érvényesül', '##ését', 'ne', 'korlátozza', '”', '–', 'fogalmaz', 'a', 'levélben', '.', 'Sopron', '##i', 'azért', 'kezdeményezett', 'beszélgetést', ',', 'mert', 'agg', '##asztja', 'a', 'kerületi', 'diákok', 'és', 'tanárok', 'sorsa', '.', '„', 'Mi', 'tesszük', 'tovább', 'a', 'dolgunk', '##at', ':', 'száz', '##millió', '##k', '##kal', 'támogat', '##juk', 'a', 'helyi', 'iskolák', 'felújítás', '##át', ',', 'cserébe', 'csak', 'a', 'tanárok', 'és', 'diákok', 'felé', 'mutatott', 'em', '##pat', '##ikus', 'hozzáállás', '##t', 'vár', '##nánk', '”', '–', 'írja', 'a', 'Facebook', '-', 'bejegyzés', '##ében', '.', 'Múlt', 'pénteken', 'a', 'VI', '.', 'kerületi', 'Kölcs', '##ey', 'Ferenc', 'Gimnázium', 'több', ',', 'a', 'polgári', 'enged', '##etlenség', '##ben', 'résztvevő', 'tanár', '##át', 'azonnali', 'hatállyal', 'men', '##esztett', '##ék', '.', 'A', 'tank', '##erület', 'azt', 'írta', 'a', 'Tel', '##ex', '##nek', ',', 'hogy', 'az', 'érintett', 'tanárok', 'felment', '##ése', 'indokolt', ',', 'mert', 'a', 'tanárok', 'írásbeli', 'figyelmeztetés', 'után', 'is', 'többször', 'megismétel', '##ték', '„', 'jogszerű', '##tlen', 'cselekedet', '##üket', '”', '.', 'Még', 'aznap', 'több', 'száz', '##an', 'tiltak', '##oztak', 'a', 'döntés', 'ellen', 'a', 'gimnázium', 'előtt', ',', 'majd', 'a', 'héten', 'tovább', 'folytató', '##d', '##tak', 'a', 'tüntet', '##ések', '.', 'A', 'men', '##esztett', 'tanárok', 'munkaügyi', 'pert', 'indít', '##anak', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now evaluate the whole test set\n",
        "batch_size = 64\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size)\n",
        "scores = rouge.compute(predictions=results[\"pred_summary\"], references=results[\"Lead\"], rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
        "print(scores['rouge1'].mid)\n",
        "print(scores['rouge2'].mid)\n",
        "print(scores['rougeL'].mid)"
      ],
      "metadata": {
        "id": "rfSj4EbUQKoD",
        "outputId": "7e3753fb-97a0-4880-e211-5b591083b3fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "edd06650f0bb4b91a1f01b2774485b6a",
            "3258d8d7075144a18307b3597c15b17f",
            "fb6e65629d454d9595c2fab848a1492f",
            "1dd62ce1e7a340c6a222e2a63d48290f",
            "8a0b1d8dd7204ba6a8bc19ada930c76a",
            "bfa08116f8224e7abb711dc7020f5bb4",
            "eeebc942394f4233ac0281b9c64d517d",
            "806eb2bce94443a99466ae4c0fa2549f",
            "687ece2cf3af4668b2ab67f05e3f3ad1",
            "7f5bb0c30dca4ed3916e0adbd548c5fd",
            "ce54f355f588410287e26e8eeada058b"
          ]
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "edd06650f0bb4b91a1f01b2774485b6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Score(precision=0.14045474872072017, recall=0.07940448993799529, fmeasure=0.09689360803523799)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see a couple examples\n",
        "print(results['Lead'][3])\n",
        "print(results['pred_summary'][3])\n",
        "print(\"\")\n",
        "print(results['Lead'][5])\n",
        "print(results['pred_summary'][5])\n",
        "print(\"\")\n",
        "print(results['Lead'][9])\n",
        "print(results['pred_summary'][9])"
      ],
      "metadata": {
        "id": "DLhRYQj16JrF",
        "outputId": "d587d00c-d7b0-40bb-c9fd-d46a500d6442",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elon Musk visszaengedné Donald Trumpot a Twitterre. A milliárdos hibának tartja a 2021-ben hozott döntést a volt amerikai elnök végleges tiltásáról.\n",
            "Elon Musk szerint hiba volt, hogy nem volt helyes letiltani Donald Trump volt amerikai elnök fiókját.\n",
            "\n",
            "Messit látni és beleszeretni a Troyes-ba. A PSG hétvégi meccsén a hangulat közelebb volt a Fővárosi Nagycirkuszban tapasztaltakhoz, Messi és Neymar labdaérintésénél sikongatott a nézőtér, a hazai góloknál tűzijáték volt és hivatásos...\n",
            "A Paris Saint - Germain szurkolói nem csak a Paris Saint - Germain elleni meccsre járnak el, hanem a Paris Saint - Germain elleni meccsre is.\n",
            "\n",
            "Kína járványkezelési stratégiája fenntarthatatlan, ráadásul emberjogi és gazdasági szempontból is aggályos a WHO szerint. A „dinamikus zéró-Covid” miatt van több mint egy hónapja vesztegzár alatt a 25 milliós Sanghaj.\n",
            "A WHO szerint a kínai járványkezelés fenntartása fenntarthatatlan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the sentences are mostly correct grammatically, but their meaning leaves a lot to be desired."
      ],
      "metadata": {
        "id": "2wzSJdlKO9ZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train further"
      ],
      "metadata": {
        "id": "-IQ1UmraYIWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#already default\n",
        "#model.config.decoder_start_token_id == tokenizer.cls_token_id\n",
        "#model.config.eos_token_id == tokenizer.sep_token_id\n",
        "#model.config.pad_token_id == tokenizer.pad_token_id\n",
        "#model.config.vocab_size == model.config.encoder.vocab_size"
      ],
      "metadata": {
        "id": "VCWk8auo-Z6w"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#még nem akarom állítgatni\n",
        "#model.config.max_length = 142\n",
        "#model.config.min_length = 56\n",
        "#model.config.no_repeat_ngram_size = 3\n",
        "#model.config.early_stopping = True\n",
        "#model.config.length_penalty = 2.0\n",
        "#model.config.num_beams = 4"
      ],
      "metadata": {
        "id": "ftHFWocn-_cB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm seq2seq_trainer.py\n",
        "!rm seq2seq_training_args.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py\n",
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_training_args.py"
      ],
      "metadata": {
        "id": "1C0TSMQnFkX8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install git-python==1.0.3\n",
        "!pip install rouge_score\n",
        "!pip install sacrebleu"
      ],
      "metadata": {
        "id": "Nn_rY9ayGo7_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seq2seq_trainer import Seq2SeqTrainer\n",
        "from seq2seq_training_args import Seq2SeqTrainingArguments"
      ],
      "metadata": {
        "id": "IQ5TlgFRG61z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original training args\n",
        "training_args = torch.load('/content/model/model/training_args.bin')\n",
        "training_args"
      ],
      "metadata": {
        "id": "ZLJhxQuYauCQ",
        "outputId": "a2747cac-9e66-49c5-ddd8-4a29bf2dcbee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2SeqTrainingArguments(output_dir='/mnt/idms/home/botondbarta/trainers_wo_nlc', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=13, per_device_eval_batch_size=13, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=5e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=8000, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/mnt/idms/home/botondbarta/trainers_wo_nlc/runs/Oct29_18-17-26_gpu100.ilab.sztaki.hu', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=500, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=3400, save_total_limit=3, save_on_each_node=False, no_cuda=False, use_mps_device=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=True, fp16_opt_level='O1', half_precision_backend='cuda_amp', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=3400, dataloader_num_workers=0, past_index=-1, run_name='/mnt/idms/home/botondbarta/trainers_wo_nlc', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='loss', greater_is_better=False, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, fsdp_transformer_layer_cls_to_wrap=None, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_HF: 'adamw_hf'>, adafactor=False, group_by_length=False, length_column_name='length', report_to=[], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=False, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last', ddp_timeout=1800, sortish_sampler=False, predict_with_generate=True, generation_max_length=None, generation_num_beams=None)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=True, \n",
        "    output_dir=\"./output\",\n",
        "    logging_steps=16,\n",
        "    save_steps=10,\n",
        "    eval_steps=16,\n",
        "    gradient_accumulation_steps=1, \n",
        "    eval_accumulation_steps=None, \n",
        "    eval_delay=0, \n",
        "    learning_rate=5e-05, \n",
        "    weight_decay=0.01, \n",
        "    adam_beta1=0.9, \n",
        "    adam_beta2=0.999, \n",
        "    adam_epsilon=1e-08, \n",
        "    max_grad_norm=1.0, \n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zBJzzbVVG9yZ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "metadata": {
        "id": "BcmBQtA0LoHh"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Em_YUiEpMv0a",
        "outputId": "90444630-6526-4dbf-c134-94f0127806d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 6570\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1233\n",
            "  Number of trainable parameters = 249636609\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='145' max='1233' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 145/1233 12:09 < 1:32:31, 0.20 it/s, Epoch 0.35/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge2 Precision</th>\n",
              "      <th>Rouge2 Recall</th>\n",
              "      <th>Rouge2 Fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>3.263400</td>\n",
              "      <td>2.000068</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.276000</td>\n",
              "      <td>0.195544</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.166200</td>\n",
              "      <td>0.163389</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.147600</td>\n",
              "      <td>0.144132</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.064500</td>\n",
              "      <td>0.020353</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.030300</td>\n",
              "      <td>0.004106</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>0.027600</td>\n",
              "      <td>0.021213</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>0.027500</td>\n",
              "      <td>0.040037</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='88' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/88 00:11 < 00:57, 1.26 it/s]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./output/checkpoint-10\n",
            "Configuration saved in ./output/checkpoint-10/config.json\n",
            "Model weights saved in ./output/checkpoint-10/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-20\n",
            "Configuration saved in ./output/checkpoint-20/config.json\n",
            "Model weights saved in ./output/checkpoint-20/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to ./output/checkpoint-30\n",
            "Configuration saved in ./output/checkpoint-30/config.json\n",
            "Model weights saved in ./output/checkpoint-30/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-40\n",
            "Configuration saved in ./output/checkpoint-40/config.json\n",
            "Model weights saved in ./output/checkpoint-40/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-50\n",
            "Configuration saved in ./output/checkpoint-50/config.json\n",
            "Model weights saved in ./output/checkpoint-50/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to ./output/checkpoint-60\n",
            "Configuration saved in ./output/checkpoint-60/config.json\n",
            "Model weights saved in ./output/checkpoint-60/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-70\n",
            "Configuration saved in ./output/checkpoint-70/config.json\n",
            "Model weights saved in ./output/checkpoint-70/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-80\n",
            "Configuration saved in ./output/checkpoint-80/config.json\n",
            "Model weights saved in ./output/checkpoint-80/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to ./output/checkpoint-90\n",
            "Configuration saved in ./output/checkpoint-90/config.json\n",
            "Model weights saved in ./output/checkpoint-90/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-100\n",
            "Configuration saved in ./output/checkpoint-100/config.json\n",
            "Model weights saved in ./output/checkpoint-100/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to ./output/checkpoint-110\n",
            "Configuration saved in ./output/checkpoint-110/config.json\n",
            "Model weights saved in ./output/checkpoint-110/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-120\n",
            "Configuration saved in ./output/checkpoint-120/config.json\n",
            "Model weights saved in ./output/checkpoint-120/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./output/checkpoint-130\n",
            "Configuration saved in ./output/checkpoint-130/config.json\n",
            "Model weights saved in ./output/checkpoint-130/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to ./output/checkpoint-140\n",
            "Configuration saved in ./output/checkpoint-140/config.json\n",
            "Model weights saved in ./output/checkpoint-140/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-80f1b3ecf765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1827\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2087\u001b[0m                     )\n\u001b[1;32m   2088\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2089\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2801\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2804\u001b[0m         )\n\u001b[1;32m   2805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2983\u001b[0m                 \u001b[0mlosses_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlosses_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2984\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2985\u001b[0;31m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad_across_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2986\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2987\u001b[0m                 \u001b[0mlabels_host\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlabels_host\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnested_concat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_pad_across_processes\u001b[0;34m(self, tensor, pad_index)\u001b[0m\n\u001b[1;32m   3131\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3132\u001b[0m         \u001b[0;31m# Gather all sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3133\u001b[0;31m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3134\u001b[0m         \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the partially trained model\n",
        "model = EncoderDecoderModel.from_pretrained(\"/content/output/checkpoint-140\").to(device)"
      ],
      "metadata": {
        "id": "utKitw18ja9z",
        "outputId": "ee625450-fc20-43a2-ea28-21a40678895e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/output/checkpoint-140/config.json\n",
            "Model config EncoderDecoderConfig {\n",
            "  \"_commit_hash\": null,\n",
            "  \"_name_or_path\": \"/content/model/model/pytorch_model.bin\",\n",
            "  \"architectures\": [\n",
            "    \"EncoderDecoderModel\"\n",
            "  ],\n",
            "  \"decoder\": {\n",
            "    \"_name_or_path\": \"SZTAKI-HLT/hubert-base-cc\",\n",
            "    \"add_cross_attention\": true,\n",
            "    \"architectures\": null,\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": true,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.24.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 32001\n",
            "  },\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"encoder\": {\n",
            "    \"_name_or_path\": \"SZTAKI-HLT/hubert-base-cc\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": null,\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.24.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 32001\n",
            "  },\n",
            "  \"eos_token_id\": 3,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"model_type\": \"encoder-decoder\",\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": null,\n",
            "  \"vocab_size\": 32001\n",
            "}\n",
            "\n",
            "loading weights file /content/output/checkpoint-140/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
            "\n",
            "All the weights of EncoderDecoderModel were initialized from the model checkpoint at /content/output/checkpoint-140.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation after further training"
      ],
      "metadata": {
        "id": "5mkn2IREvN2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size)\n",
        "scores = rouge.compute(predictions=results[\"pred_summary\"], references=results[\"Lead\"], rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
        "print(scores['rouge1'].mid)\n",
        "print(scores['rouge2'].mid)\n",
        "print(scores['rougeL'].mid)"
      ],
      "metadata": {
        "id": "OXLs1mJ7vRJJ",
        "outputId": "ec62bf52-fc56-4edd-b218-5638bc08adf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5cbfbfa89c044121b38b4f6b8fa15410",
            "907b8f4133644537a554a099d281cdbc",
            "80e982522d864aefb8931418b0f4f824",
            "2eb452144d7f4c4abdde2b96cad11e8a",
            "9d1f17aca30941a58007d511232f4944",
            "3fa9f3a15a5a474bbe2fca591f9cd426",
            "56586341965c48ae8387c8007c73cd01",
            "141154b6623c4f989d8ef49f8e90a032",
            "417e8d7bf96048dda29c9d0041545476",
            "37cafb9bd4c1411aa3b253fe901c2cb0",
            "b068ca62287a460ebd3f5a65ad0952d0"
          ]
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cbfbfa89c044121b38b4f6b8fa15410"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Score(precision=0.009718281248130407, recall=0.016238665502035506, fmeasure=0.01157736288744703)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save to csv\n",
        "results_df = pd.DataFrame({})\n",
        "results_df['Lead'] = results['Lead']\n",
        "results_df['pred_summary'] = results['pred_summary']\n",
        "results_df['Textbody'] = results['Textbody']\n",
        "results_df.to_csv('results_df.csv', index=False)"
      ],
      "metadata": {
        "id": "-nl61rc0XRg6"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df['pred_summary'].iloc[40] #lmao"
      ],
      "metadata": {
        "id": "ifhb4_rMZmmk",
        "outputId": "14b59112-686f-41f1-b4be-c0f7fa076706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák Novák'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4CTynI71bmtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}