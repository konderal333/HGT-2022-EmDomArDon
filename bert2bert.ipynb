{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c1e515fa0ac49d090e9592dab6077a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f31745167f5c4ef4bca48283681b425b",
              "IPY_MODEL_b60130417fdd45d99e2a6b38a01db911",
              "IPY_MODEL_12c2779273d243e6871973d26060c457"
            ],
            "layout": "IPY_MODEL_afb11e10a02b48fbbefa11351ca75ef2"
          }
        },
        "f31745167f5c4ef4bca48283681b425b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63351fd1d9984a55aa42444400695985",
            "placeholder": "​",
            "style": "IPY_MODEL_7c83c07f3a044c84bd5d79e38ae6f917",
            "value": "Downloading builder script: "
          }
        },
        "b60130417fdd45d99e2a6b38a01db911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53eb42c6c6e4446ae7f5ba71dea8969",
            "max": 2160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9439aa56cd1145d6a2d6f6d8fbc547b8",
            "value": 2160
          }
        },
        "12c2779273d243e6871973d26060c457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd1b63af8a51492e8efbf72eac38f53e",
            "placeholder": "​",
            "style": "IPY_MODEL_58904a9155334686a8759d0d930771ee",
            "value": " 5.60k/? [00:00&lt;00:00, 191kB/s]"
          }
        },
        "afb11e10a02b48fbbefa11351ca75ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63351fd1d9984a55aa42444400695985": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c83c07f3a044c84bd5d79e38ae6f917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c53eb42c6c6e4446ae7f5ba71dea8969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9439aa56cd1145d6a2d6f6d8fbc547b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd1b63af8a51492e8efbf72eac38f53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58904a9155334686a8759d0d930771ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d88b12557fd44c1183f862bdbce96ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70da870b7fa9464196e38a1062af50be",
              "IPY_MODEL_9e6b4594fd15467eadc891452eb32d21",
              "IPY_MODEL_b722e1ad34ee4a24b74df83011e44cfb"
            ],
            "layout": "IPY_MODEL_433d877378084277baecba2cee1354f9"
          }
        },
        "70da870b7fa9464196e38a1062af50be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27d97be136024c8b925161d58f5c19b7",
            "placeholder": "​",
            "style": "IPY_MODEL_8043c348ad9642b19439af4f5fd2018a",
            "value": "100%"
          }
        },
        "9e6b4594fd15467eadc891452eb32d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb4854d09c8a4796b7013fa71a481052",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c00da71e49bf4a29b8549dfe1664a25b",
            "value": 22
          }
        },
        "b722e1ad34ee4a24b74df83011e44cfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9d811305b1149b3a79d5f8c49421989",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc2e3f60fac44478a6e488f38de1ccd",
            "value": " 22/22 [00:31&lt;00:00,  1.44s/ba]"
          }
        },
        "433d877378084277baecba2cee1354f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27d97be136024c8b925161d58f5c19b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8043c348ad9642b19439af4f5fd2018a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb4854d09c8a4796b7013fa71a481052": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c00da71e49bf4a29b8549dfe1664a25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9d811305b1149b3a79d5f8c49421989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dc2e3f60fac44478a6e488f38de1ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b0ecbd6d0834f87a82a93e525531261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d86eee5638024349a342ce56b7ff9657",
              "IPY_MODEL_70252a42d88147159d07b8745193dca6",
              "IPY_MODEL_bfaa8281e5a14d0b84c0e2dc5dc91e4d"
            ],
            "layout": "IPY_MODEL_b73b79a37e97478bb096b849747f1136"
          }
        },
        "d86eee5638024349a342ce56b7ff9657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e328f07d93a4f859182c8b5d9ed9b87",
            "placeholder": "​",
            "style": "IPY_MODEL_438bbc01a6174a8e94da117b8f773620",
            "value": "100%"
          }
        },
        "70252a42d88147159d07b8745193dca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd113ba9f6924b40b11c14253dee833b",
            "max": 88,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b2cb7a9140944f682ffac5280824429",
            "value": 88
          }
        },
        "bfaa8281e5a14d0b84c0e2dc5dc91e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e66ebf9020d14567acb1ba889205d9a8",
            "placeholder": "​",
            "style": "IPY_MODEL_0c7c7e63d5974b90aa665efe979df15e",
            "value": " 88/88 [02:41&lt;00:00,  1.63s/ba]"
          }
        },
        "b73b79a37e97478bb096b849747f1136": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e328f07d93a4f859182c8b5d9ed9b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438bbc01a6174a8e94da117b8f773620": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd113ba9f6924b40b11c14253dee833b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b2cb7a9140944f682ffac5280824429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e66ebf9020d14567acb1ba889205d9a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c7c7e63d5974b90aa665efe979df15e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konderal333/HGT-2022-EmDomArDon/blob/main/bert2bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models and data"
      ],
      "metadata": {
        "id": "l935bl02XlAr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf0Ee_SOf0qi",
        "outputId": "271e68a3-9ea8-4576-9511-f44feefb8c72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HGT-2022-EmDomArDon' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/konderal333/HGT-2022-EmDomArDon.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "metadata": {
        "id": "oLsjhiWggpKu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/HGT-2022-EmDomArDon/cikkek_10k_cleanedv1.csv')"
      ],
      "metadata": {
        "id": "gcCdIAFigtO1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().values.any())\n",
        "print(sum(df.duplicated()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_jetG8guxLJ",
        "outputId": "7a1aedc0-9c8b-441b-d43e-12f0ffe2c139"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df = df.drop_duplicates()"
      ],
      "metadata": {
        "id": "F9Wnh0wXvTnK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.apply(lambda x: x.str.strip())\n",
        "df['Textbody'] = df['Textbody'].apply(lambda x: re.sub(r\"(\\.)([A-Z])\", r'\\1 \\2', str(x))) # add missing whitespace between sentences\n",
        "\n",
        "df['Lead'] = df['Title'] + '. ' + df['Headline'] # maybe only headline and drop title?\n",
        "df = df.drop(['Title', 'Headline'],axis=1)\n",
        "df.head()\n",
        "\n",
        "#reindexing the dataframe\n",
        "df.reset_index(inplace=True)\n",
        "df = df.drop(['index'], axis=1)"
      ],
      "metadata": {
        "id": "a_Wq2IDmk9oL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8XZHCm-dgwKA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('SZTAKI-HLT/hubert-base-cc')"
      ],
      "metadata": {
        "id": "rO9me5lwgx9z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bert2bert\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5\" -O model_bert2bert.tar.gz && rm -rf /tmp/cookies.txt\n",
        "\n",
        "# model\n",
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd\" -O model.tar.gz && rm -rf /tmp/cookies.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb47813-ee22-4194-f470-76b9aa7992fa",
        "id": "OJp93I3EteNc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-29 08:10:06--  https://docs.google.com/uc?export=download&confirm=t&id=1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.24.138, 74.125.24.101, 74.125.24.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.24.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-0o-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fiukl75ibqfqrq3bmojspf9t64jadqce/1669709400000/03710960119062529382/*/1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5?e=download&uuid=71255f88-ae1c-44e9-be91-cf2b33a13b00 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-29 08:10:08--  https://doc-0o-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fiukl75ibqfqrq3bmojspf9t64jadqce/1669709400000/03710960119062529382/*/1jVivzwtgoZx38yMeZA5BthGGvoPxBZk5?e=download&uuid=71255f88-ae1c-44e9-be91-cf2b33a13b00\n",
            "Resolving doc-0o-18-docs.googleusercontent.com (doc-0o-18-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-0o-18-docs.googleusercontent.com (doc-0o-18-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2648670050 (2.5G) [application/x-gzip]\n",
            "Saving to: ‘model_bert2bert.tar.gz’\n",
            "\n",
            "model_bert2bert.tar 100%[===================>]   2.47G   160MB/s    in 12s     \n",
            "\n",
            "2022-11-29 08:10:20 (218 MB/s) - ‘model_bert2bert.tar.gz’ saved [2648670050/2648670050]\n",
            "\n",
            "--2022-11-29 08:10:22--  https://docs.google.com/uc?export=download&confirm=t&id=1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.24.138, 74.125.24.101, 74.125.24.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.24.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/316evifrtuljfkdmknm709oidp06isql/1669709400000/03710960119062529382/*/1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd?e=download&uuid=cc5e346d-50d2-4dc9-80f3-d8430c38c893 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2022-11-29 08:10:23--  https://doc-10-18-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/316evifrtuljfkdmknm709oidp06isql/1669709400000/03710960119062529382/*/1GEdOmmKZEJOD2Ei28FtVEf534-nBEcBd?e=download&uuid=cc5e346d-50d2-4dc9-80f3-d8430c38c893\n",
            "Resolving doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)... 142.251.12.132, 2404:6800:4003:c11::84\n",
            "Connecting to doc-10-18-docs.googleusercontent.com (doc-10-18-docs.googleusercontent.com)|142.251.12.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 927224269 (884M) [application/x-gzip]\n",
            "Saving to: ‘model.tar.gz’\n",
            "\n",
            "model.tar.gz        100%[===================>] 884.27M   211MB/s    in 4.9s    \n",
            "\n",
            "2022-11-29 08:10:28 (180 MB/s) - ‘model.tar.gz’ saved [927224269/927224269]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.unpack_archive('model.tar.gz', 'model')\n",
        "shutil.unpack_archive('model_bert2bert.tar.gz', 'bert2bert')"
      ],
      "metadata": {
        "id": "J5A7_9vkteNf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "bert2bert_model_path = '/content/bert2bert/model/pytorch_model.bin'\n",
        "bert2bert_config = '/content/bert2bert/model/config.json'\n",
        "\n",
        "model_path = '/content/model/model/pytorch_model.bin'\n",
        "config = '/content/model/model/config.json'\n",
        "\n",
        "bert2bert = EncoderDecoderModel.from_pretrained(bert2bert_model_path, config=bert2bert_config).to(device)\n",
        "model = EncoderDecoderModel.from_pretrained(model_path, config=config).to(device)"
      ],
      "metadata": {
        "id": "1gftlAZQ-DKl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutorial notebook:\n",
        "\n",
        "https://colab.research.google.com/drive/1WIk2bxglElfZewOHboPFNj8H44_VAyKE?usp=sharing&fbclid=IwAR2-pdnudSutvgqIlUUg4NP1Q0wJO9NQbteg_wVL9n8gsS2yMTfMp9YfC6w#scrollTo=bYmdx-W1NAky\n",
        "\n",
        "The majority of the codes found in that notebook is outdated, so we needed to make a couple of augmentations and changes in order to make them work in our environment."
      ],
      "metadata": {
        "id": "VvDFzCOSq8hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Functions to handle larger inputs than 512 tokens"
      ],
      "metadata": {
        "id": "yl-We1JlC_bD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNnjgwweEVpV",
        "outputId": "dd46a408-b93a-4704-a19a-4fe40f1e944b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-mtv2RDSrsB"
      },
      "source": [
        "<p>Method to reduce the length of sentences with more than 510 tokens:\n",
        "<p>We get the first few whole sentences until we reach 255 tokens. (Let us assume that we get n tokens from these sentences, where n&#60;255). Then we get the last few whole sentences until these reach the remaining limit of tokens (510-n).\n",
        "<p>So with this method we reduce the longer articles to texts which contain 510 tokens (or a bit less than 510), so that we get the beginning and the end of the article."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DPPAVum781B-"
      },
      "outputs": [],
      "source": [
        "def text_to_token_list(art_title, x):      \n",
        "  token_list = []\n",
        "  sen_list = []\n",
        "\n",
        "  x = re.sub(r\"(\\.)([A-Z])\", r'\\1 \\2', x) # fixes missings whitespaces between sentences\n",
        " \n",
        "  for sen in nltk.tokenize.sent_tokenize(x):\n",
        "    token_list.append(tokenizer.tokenize(sen))\n",
        "    sen_list.append(sen)\n",
        "\n",
        "  return token_list, sen_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q3rAijD680_n"
      },
      "outputs": [],
      "source": [
        "dict_of_tokens = {} \n",
        "#this dict will contain the article title as keys and the tokenized lists from the function below as values for other purposes\n",
        "\n",
        "def text_to_tokens(art_title, x):      \n",
        "  #insert the text to tokenize; first breaks text into sentences, then makes a list of lists with the i-th element being the tokenization of the i-th sentence\n",
        "  token_list = []\n",
        "\n",
        "  x = re.sub(r\"(\\.)([A-Z])\", r'\\1 \\2', x) # fixes missings whitespaces between sentences\n",
        "\n",
        "  tokens, sentences = text_to_token_list(art_title, x)  #tokens and sentences\n",
        "\n",
        "  new_text = ''      #this is the text which contains less than (or equal to) 510 tokens\n",
        "\n",
        "  #total tokennumber\n",
        "  len1 = 0\n",
        "  for i in tokens:\n",
        "    for j in i:\n",
        "      len1 += 1\n",
        "\n",
        "  #if the text is > 510 tokens, we will get the first few whole sentences (~255 tokens), and the last few whole sentences (~255 tokens)\n",
        "  if len1 > 510:\n",
        "    begin_sum = 0\n",
        "    begin_tokens = []\n",
        "    for index, elem1 in enumerate(tokens):\n",
        "      if begin_sum + len(elem1) > 255:\n",
        "        break\n",
        "      else:\n",
        "        begin_sum += len(elem1)\n",
        "        begin_tokens.append(elem1)\n",
        "        new_text = new_text + sentences[index] + \" \"   #appending the new text  \n",
        "\n",
        "    end_indexes = []\n",
        "    end_sum = 0\n",
        "    end_tokens = []\n",
        "    tokens.reverse()\n",
        "    for index, elem2 in enumerate(tokens):\n",
        "      if end_sum + len(elem2) > 510-begin_sum:\n",
        "        break\n",
        "      else:\n",
        "        end_sum += len(elem2)\n",
        "        end_tokens.append(elem2)\n",
        "        end_indexes.append(-index-1)\n",
        "\n",
        "    #finally reconstructing the text which has less than (or equal to) 510 tokens \n",
        "    end_indexes.reverse()\n",
        "    for end_index in end_indexes:\n",
        "      new_text = new_text + sentences[end_index] + \" \"\n",
        "\n",
        "\n",
        "    end_tokens.reverse()\n",
        "    final_tokens = []\n",
        "    for elem3 in begin_tokens:\n",
        "      final_tokens.append(elem3)\n",
        "    for elem4 in end_tokens:\n",
        "      final_tokens.append(elem4)\n",
        "\n",
        "    dict_of_tokens[art_title] = final_tokens\n",
        "    return new_text.strip()\n",
        "\n",
        "  #if the text is < 510 tokens, we do not have to get the beginning and the end, we can use the whole text\n",
        "  else:\n",
        "    for sen in nltk.tokenize.sent_tokenize(x):\n",
        "      new_text = new_text + sen + \" \"\n",
        "      token_list.append(tokenizer.tokenize(sen))\n",
        "\n",
        "    dict_of_tokens[art_title] = token_list\n",
        "    return new_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lKPzoUMQFR1U"
      },
      "outputs": [],
      "source": [
        "# making the BERT tokenized sentences and the reduced sentences from each article\n",
        "\n",
        "for i in range(len(df.Lead)):\n",
        "  new_text = text_to_tokens(df.Lead[i].strip(), df.Textbody[i])\n",
        "  df.at[i, 'Textbody'] = new_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RKs_y_INE4tk"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statistics\n",
        "\n",
        "number_of_tokens_all = []\n",
        "\n",
        "for tokens in dict_of_tokens.values():\n",
        "  length = 0\n",
        "  for lists in tokens:\n",
        "    length += len(lists)\n",
        "  number_of_tokens_all.append(length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SouF0fzoJBaS",
        "outputId": "65795fd2-e864-46df-9434-a3d3783c8fc8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.hist(number_of_tokens_all, bins=100, density=False)\n",
        "plt.title('Distribution of number of tokens generated from articles')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoCOHObVJD3A",
        "outputId": "c25f6fe0-257f-4237-ab24-f1d40fe39055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# number of articles with tokens more that 510:\n",
        "print(np.sum(np.asarray(number_of_tokens_all) > 510))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if the new texts really has the appropriate number of tokens\n",
        "for index, row in df.iterrows():\n",
        "  x = nltk.tokenize.sent_tokenize(row['Textbody'])\n",
        "  all_len = 0\n",
        "  for elem in x:\n",
        "    all_len += len(tokenizer.tokenize(elem))\n",
        "  if all_len > 510:\n",
        "    print(index)"
      ],
      "metadata": {
        "id": "YpqMn94PIl_p"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process data"
      ],
      "metadata": {
        "id": "NvtkSH6FXrZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_to_model_inputs(batch):\n",
        "        # Tokenize the input and target data\n",
        "        inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512)\n",
        "        outputs = tokenizer(batch['Lead'], padding='max_length', truncation=True, max_length=512)\n",
        "\n",
        "        batch['input_ids'] = inputs.input_ids\n",
        "        batch['attention_mask'] = inputs.attention_mask\n",
        "        batch['decoder_input_ids'] = outputs.input_ids\n",
        "        batch['decoder_attention_mask'] = outputs.attention_mask\n",
        "        batch['labels'] = outputs.input_ids.copy()\n",
        "\n",
        "        # batch['labels'] = [[-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
        "        #                    for labels in batch['labels']]\n",
        "        batch['labels'] = [-100 if token == tokenizer.pad_token_id else token for token in batch['labels']]\n",
        "\n",
        "        return batch"
      ],
      "metadata": {
        "id": "uBAQRVkUeV3d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number of articles\n",
        "df.shape[0]"
      ],
      "metadata": {
        "id": "m5Hdl4WlsYKO",
        "outputId": "09a4c34d-f129-4b7b-82bf-d332c590fa5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9386"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full Data\n",
        "\n",
        "# split is 70-15-15\n",
        "\n",
        "train_data = df.iloc[0:int(np.floor(df.shape[0]*0.7))]\n",
        "val_data = df.iloc[int(np.floor(df.shape[0]*0.7)):int(np.floor(df.shape[0]*0.85))]\n",
        "test_data = df.iloc[int(np.floor(df.shape[0]*0.85)):]\n",
        "\n",
        "\n",
        "#Partial Data\n",
        "#train_data = df.iloc[0:20]\n",
        "#val_data = df.iloc[20:30]\n",
        "#test_data = df.iloc[30:40]\n",
        "\n",
        "#train_data.reset_index(inplace=True)\n",
        "#val_data.reset_index(inplace=True)\n",
        "#test_data.reset_index(inplace=True)\n",
        "\n",
        "#train_data = train_data.drop(['index'], axis=1)\n",
        "#val_data = val_data.drop(['index'], axis=1)\n",
        "#test_data = test_data.drop(['index'], axis=1)"
      ],
      "metadata": {
        "id": "0koyJhZXmQPF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transforming the train and validation data\n",
        "train_data = train_data.apply(process_data_to_model_inputs, axis=1)\n",
        "train_data = train_data.drop(['Textbody', 'Lead'], axis=1)\n",
        "\n",
        "val_data = val_data.apply(process_data_to_model_inputs, axis=1)\n",
        "val_data = val_data.drop(['Textbody', 'Lead'], axis=1)"
      ],
      "metadata": {
        "id": "vPUFBFq3jXip"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Voqr9PbmvebJ",
        "outputId": "83969f86-fd21-4e5e-dd10-7aba37dcdda6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           input_ids  \\\n",
              "0  [2, 2155, 7155, 2524, 4046, 4341, 15269, 14826...   \n",
              "1  [2, 30196, 9688, 11787, 11628, 2005, 11149, 22...   \n",
              "2  [2, 4405, 2546, 8984, 3576, 2079, 2005, 16667,...   \n",
              "3  [2, 22158, 6688, 29536, 2005, 13549, 31735, 12...   \n",
              "4  [2, 10708, 11447, 2685, 2066, 9763, 31736, 200...   \n",
              "\n",
              "                                      attention_mask  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                   decoder_input_ids  \\\n",
              "0  [2, 21086, 2018, 6480, 2045, 26204, 14350, 804...   \n",
              "1  [2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...   \n",
              "2  [2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...   \n",
              "3  [2, 12930, 12887, 6704, 7671, 2837, 20664, 297...   \n",
              "4  [2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...   \n",
              "\n",
              "                              decoder_attention_mask  \\\n",
              "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
              "\n",
              "                                              labels  \n",
              "0  [2, 21086, 2018, 6480, 2045, 26204, 14350, 804...  \n",
              "1  [2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...  \n",
              "2  [2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...  \n",
              "3  [2, 12930, 12887, 6704, 7671, 2837, 20664, 297...  \n",
              "4  [2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b924cc-ad35-4c48-99ab-3564528aa924\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_ids</th>\n",
              "      <th>attention_mask</th>\n",
              "      <th>decoder_input_ids</th>\n",
              "      <th>decoder_attention_mask</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[2, 2155, 7155, 2524, 4046, 4341, 15269, 14826...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 21086, 2018, 6480, 2045, 26204, 14350, 804...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 21086, 2018, 6480, 2045, 26204, 14350, 804...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[2, 30196, 9688, 11787, 11628, 2005, 11149, 22...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 28589, 6997, 2039, 5833, 6505, 2094, 2005,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[2, 4405, 2546, 8984, 3576, 2079, 2005, 16667,...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 5388, 28306, 7996, 2005, 16667, 3021, 2653...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[2, 22158, 6688, 29536, 2005, 13549, 31735, 12...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 12930, 12887, 6704, 7671, 2837, 20664, 297...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 12930, 12887, 6704, 7671, 2837, 20664, 297...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[2, 10708, 11447, 2685, 2066, 9763, 31736, 200...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...</td>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "      <td>[2, 2930, 29814, 2066, 9763, 2033, 2718, 31741...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b924cc-ad35-4c48-99ab-3564528aa924')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21b924cc-ad35-4c48-99ab-3564528aa924 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21b924cc-ad35-4c48-99ab-3564528aa924');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "i2Ntmb6Bi9bY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to arrow dataset (easier to use)\n",
        "import pyarrow as pa\n",
        "import pyarrow.dataset as ds\n",
        "from datasets import Dataset\n",
        "\n",
        "train_data = Dataset(pa.Table.from_pandas(train_data))\n",
        "val_data = Dataset(pa.Table.from_pandas(val_data))\n",
        "test_data = Dataset(pa.Table.from_pandas(test_data))\n",
        "\n",
        "# format type\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yz9aXIWvguOJ",
        "outputId": "c917896c-20aa-460a-dd8c-86d4d617aae9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'decoder_input_ids', 'decoder_attention_mask', 'labels'],\n",
              "    num_rows: 6570\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the train and validation sets to tensors\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ],
      "metadata": {
        "id": "AtoQw3txhJye"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example\n",
        "train_data[\"labels\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz2hUNUaf7Mq",
        "outputId": "b159cd78-2d7b-4368-cd9c-0e9d26459431"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2, 21086,  2018,  ...,  -100,  -100,  -100],\n",
              "        [    2, 28589,  6997,  ...,  -100,  -100,  -100],\n",
              "        [    2,  5388, 28306,  ...,  -100,  -100,  -100],\n",
              "        ...,\n",
              "        [    2,  2155,  3165,  ...,  -100,  -100,  -100],\n",
              "        [    2,  3512,  2664,  ...,  -100,  -100,  -100],\n",
              "        [    2,  5753,  2336,  ...,  -100,  -100,  -100]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction and evaluation before training"
      ],
      "metadata": {
        "id": "nE1kDLgVYQn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "!pip install rouge_score\n",
        "import datasets\n",
        "rouge = datasets.load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "34fJFTXTuaHP",
        "outputId": "3123d9ce-8202-4822-d53e-10d54ee400b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "9c1e515fa0ac49d090e9592dab6077a9",
            "f31745167f5c4ef4bca48283681b425b",
            "b60130417fdd45d99e2a6b38a01db911",
            "12c2779273d243e6871973d26060c457",
            "afb11e10a02b48fbbefa11351ca75ef2",
            "63351fd1d9984a55aa42444400695985",
            "7c83c07f3a044c84bd5d79e38ae6f917",
            "c53eb42c6c6e4446ae7f5ba71dea8969",
            "9439aa56cd1145d6a2d6f6d8fbc547b8",
            "fd1b63af8a51492e8efbf72eac38f53e",
            "58904a9155334686a8759d0d930771ee"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=923ff415fb96de0410c0826d0dcd2f163ce37b8224d30004269d4c6ab245d447\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ac/6b/38096e3c5bf1dc87911e3585875e21a3ac610348e740409c76\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c1e515fa0ac49d090e9592dab6077a9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary generation\n",
        "\n",
        "def generate_summary(batch):\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "    input_ids = inputs.input_ids.to(device)\n",
        "    attention_mask = inputs.attention_mask.to(device)\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch['pred_summary'] = output_str\n",
        "\n",
        "    return batch\n"
      ],
      "metadata": {
        "id": "9-bSOnCrM1Ct"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example article\n",
        "batch = df.iloc[10]\n",
        "batch['Textbody']"
      ],
      "metadata": {
        "id": "dkfyOxW0Q-rG",
        "outputId": "760b4c78-6e1d-4f7c-f6b0-0c83d4859d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Találkozni szeretett volna a Kölcsey Ferenc Gimnázium tanárait menesztő tankerületi vezetővel Soproni Tamás, terézvárosi polgármester. Marosi Betrix azonban nem látta indokoltnak, hogy beszélgessenek. A tankerületi vezető levelét Facebook-oldalán tette közzé a Momentum politikusa. Azt írja Marosi, hogy „természetesen a tankerületi központnak is az az érdeke, hogy az iskolában a helyzet normalizálódjon, a pedagógusok tanítsanak, a diákok tanuljanak”. A nevelés-oktatás feltételeinek biztosítása a VI. kerület állami fenntartású iskoláiban a tankerület feladata és felelőssége,„a tankerületi központ sem kíván beleszólni abba, hogy az Önkormányzat hogyan és kikkel látja el a feladatait.”A tankerületi vezető nem látja indokoltnak, hogy személyesen is találkozzon a kerület polgármesterével, mert a munkáltatói intézkedés „kizárólag a hatályos jogszabályokból fakadó lépés volt”. Marosi szerint az érintett pedagógusok a többszöri figyelmeztetés ellenére is visszatérően megszegték „a pedagógus jogviszonyból fakadó kötelezettségeket”.„Természetesen köszönettel veszem Tisztelt Polgármester Úr közreműködését, amennyiben az arra irányul, hogy a pedagógusok a jogszabályokban számukra biztosított, törvényes módon fejezzék ki véleményüket, úgy, hogy az a gyermekek tanuláshoz való jogának érvényesülését ne korlátozza” – fogalmaz a levélben. Soproni azért kezdeményezett beszélgetést, mert aggasztja a kerületi diákok és tanárok sorsa. „Mi tesszük tovább a dolgunkat: százmilliókkal támogatjuk a helyi iskolák felújítását, cserébe csak a tanárok és diákok felé mutatott empatikus hozzáállást várnánk” – írja a Facebook-bejegyzésében. Múlt pénteken a VI. kerületi Kölcsey Ferenc Gimnázium több, a polgári engedetlenségben résztvevő tanárát azonnali hatállyal menesztették. A tankerület azt írta a Telexnek, hogy az érintett tanárok felmentése indokolt, mert a tanárok írásbeli figyelmeztetés után is többször megismételték „jogszerűtlen cselekedetüket”. Még aznap több százan tiltakoztak a döntés ellen a gimnázium előtt, majd a héten tovább folytatódtak a tüntetések. A menesztett tanárok munkaügyi pert indítanak.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now the summary\n",
        "inputs = tokenizer(batch['Textbody'], padding='max_length', truncation=True, max_length=512, return_tensors='pt')\n",
        "input_ids = inputs.input_ids.to(device)\n",
        "attention_mask = inputs.attention_mask.to(device)\n",
        "outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=50)\n",
        "output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "output_str[0]"
      ],
      "metadata": {
        "id": "GrqvfI-TRIXK",
        "outputId": "2336a723-193c-4d48-8124-9856ce71f31c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Soproni Tamás szerint a tankerületi központnak is az az érdeke, hogy a tanárok és diákok tanuljanak.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original lead\n",
        "df.iloc[10]['Lead']"
      ],
      "metadata": {
        "id": "o_Lq_aLntj6n",
        "outputId": "ce2066e9-bbb0-41a0-bb33-aa4fa45f1ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Nem akart találkozni a momentumos polgármesterrel, mert ő sem akar beleszólni abba, hogy az önkormányzat hogyan és kikkel látja el a feladatait.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see the tokens\n",
        "for t in input_ids:\n",
        "    print(tokenizer.convert_ids_to_tokens(t))"
      ],
      "metadata": {
        "id": "7MuKwvBcBe5I",
        "outputId": "6c1ac3ec-0971-49b2-efcc-447161bb8f0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'Találkoz', '##ni', 'szeretett', 'volna', 'a', 'Kölcs', '##ey', 'Ferenc', 'Gimnázium', 'tanára', '##it', 'men', '##esztő', 'tank', '##erületi', 'vezető', '##vel', 'Sopron', '##i', 'Tamás', ',', 'ter', '##éz', '##városi', 'polgármester', '.', 'Maros', '##i', 'Bet', '##rix', 'azonban', 'nem', 'látta', 'indokolt', '##nak', ',', 'hogy', 'beszélg', '##essenek', '.', 'A', 'tank', '##erületi', 'vezető', 'level', '##ét', 'Facebook', '-', 'oldalán', 'tette', 'közzé', 'a', 'Mo', '##ment', '##um', 'politikus', '##a', '.', 'Azt', 'írja', 'Maros', '##i', ',', 'hogy', '„', 'természetesen', 'a', 'tank', '##erületi', 'központ', '##nak', 'is', 'az', 'az', 'érdeke', ',', 'hogy', 'az', 'iskolában', 'a', 'helyzet', 'norm', '##alizál', '##ódjon', ',', 'a', 'pedagógusok', 'tanít', '##sanak', ',', 'a', 'diákok', 'tanul', '##janak', '”', '.', 'A', 'nevelés', '-', 'oktatás', 'feltételeinek', 'biztosítása', 'a', 'VI', '.', 'kerület', 'állami', 'fenntart', '##ású', 'iskol', '##áiban', 'a', 'tank', '##erület', 'feladata', 'és', 'felelőssége', ',', '„', 'a', 'tank', '##erületi', 'központ', 'sem', 'kíván', 'beleszól', '##ni', 'abba', ',', 'hogy', 'az', 'Önkormányzat', 'hogyan', 'és', 'kik', '##kel', 'látja', 'el', 'a', 'feladatait', '.', '”', 'A', 'tank', '##erületi', 'vezető', 'nem', 'látja', 'indokolt', '##nak', ',', 'hogy', 'személyesen', 'is', 'találkoz', '##zon', 'a', 'kerület', 'polgármester', '##ével', ',', 'mert', 'a', 'munkáltatói', 'intézkedés', '„', 'kizárólag', 'a', 'hatályos', 'jogszabályok', '##ból', 'fakadó', 'lépés', 'volt', '”', '.', 'Maros', '##i', 'szerint', 'az', 'érintett', 'pedagógusok', 'a', 'többszöri', 'figyelmeztetés', 'ellenére', 'is', 'visszatérő', '##en', 'megszeg', '##ték', '„', 'a', 'pedagógus', 'jogviszony', '##ból', 'fakadó', 'kötelezettségek', '##et', '”', '.', '„', 'Természetesen', 'köszönet', '##tel', 'veszem', 'Tisztelt', 'Polgármester', 'Úr', 'közreműködés', '##ét', ',', 'amennyiben', 'az', 'arra', 'irányul', ',', 'hogy', 'a', 'pedagógusok', 'a', 'jogszabályokban', 'számukra', 'biztosított', ',', 'törvényes', 'módon', 'feje', '##z', '##zék', 'ki', 'vélemény', '##üket', ',', 'úgy', ',', 'hogy', 'az', 'a', 'gyermekek', 'tanulás', '##hoz', 'való', 'jogának', 'érvényesül', '##ését', 'ne', 'korlátozza', '”', '–', 'fogalmaz', 'a', 'levélben', '.', 'Sopron', '##i', 'azért', 'kezdeményezett', 'beszélgetést', ',', 'mert', 'agg', '##asztja', 'a', 'kerületi', 'diákok', 'és', 'tanárok', 'sorsa', '.', '„', 'Mi', 'tesszük', 'tovább', 'a', 'dolgunk', '##at', ':', 'száz', '##millió', '##k', '##kal', 'támogat', '##juk', 'a', 'helyi', 'iskolák', 'felújítás', '##át', ',', 'cserébe', 'csak', 'a', 'tanárok', 'és', 'diákok', 'felé', 'mutatott', 'em', '##pat', '##ikus', 'hozzáállás', '##t', 'vár', '##nánk', '”', '–', 'írja', 'a', 'Facebook', '-', 'bejegyzés', '##ében', '.', 'Múlt', 'pénteken', 'a', 'VI', '.', 'kerületi', 'Kölcs', '##ey', 'Ferenc', 'Gimnázium', 'több', ',', 'a', 'polgári', 'enged', '##etlenség', '##ben', 'résztvevő', 'tanár', '##át', 'azonnali', 'hatállyal', 'men', '##esztett', '##ék', '.', 'A', 'tank', '##erület', 'azt', 'írta', 'a', 'Tel', '##ex', '##nek', ',', 'hogy', 'az', 'érintett', 'tanárok', 'felment', '##ése', 'indokolt', ',', 'mert', 'a', 'tanárok', 'írásbeli', 'figyelmeztetés', 'után', 'is', 'többször', 'megismétel', '##ték', '„', 'jogszerű', '##tlen', 'cselekedet', '##üket', '”', '.', 'Még', 'aznap', 'több', 'száz', '##an', 'tiltak', '##oztak', 'a', 'döntés', 'ellen', 'a', 'gimnázium', 'előtt', ',', 'majd', 'a', 'héten', 'tovább', 'folytató', '##d', '##tak', 'a', 'tüntet', '##ések', '.', 'A', 'men', '##esztett', 'tanárok', 'munkaügyi', 'pert', 'indít', '##anak', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now evaluate the whole test set\n",
        "batch_size = 64\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size)\n",
        "scores = rouge.compute(predictions=results[\"pred_summary\"], references=results[\"Lead\"], rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
        "print(scores['rouge1'].mid)\n",
        "print(scores['rouge2'].mid)\n",
        "print(scores['rougeL'].mid)"
      ],
      "metadata": {
        "id": "rfSj4EbUQKoD",
        "outputId": "56e8f05c-1bc9-4c70-f2c6-881ab1f6442c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "d88b12557fd44c1183f862bdbce96ba0",
            "70da870b7fa9464196e38a1062af50be",
            "9e6b4594fd15467eadc891452eb32d21",
            "b722e1ad34ee4a24b74df83011e44cfb",
            "433d877378084277baecba2cee1354f9",
            "27d97be136024c8b925161d58f5c19b7",
            "8043c348ad9642b19439af4f5fd2018a",
            "cb4854d09c8a4796b7013fa71a481052",
            "c00da71e49bf4a29b8549dfe1664a25b",
            "e9d811305b1149b3a79d5f8c49421989",
            "9dc2e3f60fac44478a6e488f38de1ccd"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d88b12557fd44c1183f862bdbce96ba0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score(precision=0.23944815939682285, recall=0.21487622124993647, fmeasure=0.2129863951537077)\n",
            "Score(precision=0.0684007925837109, recall=0.06217603449407283, fmeasure=0.0612514175416625)\n",
            "Score(precision=0.18924766443809785, recall=0.1704140025053566, fmeasure=0.16827233943296932)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see a couple examples\n",
        "print(results['Lead'][3])\n",
        "print(results['pred_summary'][3])\n",
        "print(\"\")\n",
        "print(results['Lead'][5])\n",
        "print(results['pred_summary'][5])\n",
        "print(\"\")\n",
        "print(results['Lead'][9])\n",
        "print(results['pred_summary'][9])"
      ],
      "metadata": {
        "id": "DLhRYQj16JrF",
        "outputId": "203e1f97-1150-40d0-b235-abecac44f8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A milliárdos hibának tartja a 2021-ben hozott döntést a volt amerikai elnök végleges tiltásáról.\n",
            "Elon Musk szerint hiba volt, hogy nem volt helyes letiltani Donald Trump volt amerikai elnök fiókját.\n",
            "\n",
            "A PSG hétvégi meccsén a hangulat közelebb volt a Fővárosi Nagycirkuszban tapasztaltakhoz, Messi és Neymar labdaérintésénél sikongatott a nézőtér, a hazai góloknál tűzijáték volt és hivatásos...\n",
            "A Paris SG - Troyes francia bajnoki meccs után a Paris SG szurkolói a Parc des Princes stadionban ünnepelték a PSG - t.\n",
            "\n",
            "A „dinamikus zéró-Covid” miatt van több mint egy hónapja vesztegzár alatt a 25 milliós Sanghaj.\n",
            "A WHO szerint a kínai járványkezelés fenntartása fenntarthatatlan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the sentences are mostly correct grammatically, but their meaning leaves a lot to be desired."
      ],
      "metadata": {
        "id": "2wzSJdlKO9ZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train further"
      ],
      "metadata": {
        "id": "-IQ1UmraYIWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "!pip install rouge_score\n",
        "import datasets\n",
        "rouge = datasets.load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "gyEqFIZ9N_3m",
        "outputId": "838f8a92-7767-4c7f-a3ec-a54ced295210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.6)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk->rouge_score) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#already default\n",
        "#model.config.decoder_start_token_id == tokenizer.cls_token_id\n",
        "#model.config.eos_token_id == tokenizer.sep_token_id\n",
        "#model.config.pad_token_id == tokenizer.pad_token_id\n",
        "#model.config.vocab_size == model.config.encoder.vocab_size"
      ],
      "metadata": {
        "id": "VCWk8auo-Z6w"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#még nem akarom állítgatni\n",
        "#model.config.max_length = 142\n",
        "#model.config.min_length = 56\n",
        "#model.config.no_repeat_ngram_size = 3\n",
        "#model.config.early_stopping = True\n",
        "#model.config.length_penalty = 2.0\n",
        "#model.config.num_beams = 4"
      ],
      "metadata": {
        "id": "ftHFWocn-_cB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "#!rm seq2seq_trainer.py\n",
        "#!rm seq2seq_training_args.py\n",
        "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_trainer.py\n",
        "#!wget https://raw.githubusercontent.com/huggingface/transformers/main/examples/legacy/seq2seq/seq2seq_training_args.py"
      ],
      "metadata": {
        "id": "1C0TSMQnFkX8"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#%%capture\n",
        "#!pip install git-python==1.0.3\n",
        "#!pip install rouge_score\n",
        "#!pip install sacrebleu"
      ],
      "metadata": {
        "id": "Nn_rY9ayGo7_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from seq2seq_trainer import Seq2SeqTrainer\n",
        "#from seq2seq_training_args import Seq2SeqTrainingArguments"
      ],
      "metadata": {
        "id": "IQ5TlgFRG61z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "\n",
        "batch_size = 6\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    fp16=True, \n",
        "    output_dir=\"./output\",\n",
        "    generation_max_length=64,\n",
        "    logging_steps=16,\n",
        "    save_steps=48,\n",
        "    eval_steps=16,\n",
        "    gradient_accumulation_steps=1, \n",
        "    eval_accumulation_steps=None, \n",
        "    eval_delay=0, \n",
        "    learning_rate=5e-08, \n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zBJzzbVVG9yZ"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge1_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge1_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge1_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ],
      "metadata": {
        "id": "BcmBQtA0LoHh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data,\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "Em_YUiEpMv0a",
        "outputId": "c3e2d49d-e254-4afa-c0a3-d044697436d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 6570\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 6\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 6\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3285\n",
            "  Number of trainable parameters = 249636609\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='193' max='3285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 193/3285 1:06:44 < 18:00:20, 0.05 it/s, Epoch 0.18/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1 Precision</th>\n",
              "      <th>Rouge1 Recall</th>\n",
              "      <th>Rouge1 Fmeasure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>10.246000</td>\n",
              "      <td>10.654867</td>\n",
              "      <td>0.366500</td>\n",
              "      <td>0.203700</td>\n",
              "      <td>0.250300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>9.733400</td>\n",
              "      <td>10.130753</td>\n",
              "      <td>0.364700</td>\n",
              "      <td>0.201700</td>\n",
              "      <td>0.248000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>9.508800</td>\n",
              "      <td>9.733730</td>\n",
              "      <td>0.362500</td>\n",
              "      <td>0.201900</td>\n",
              "      <td>0.248100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>9.231900</td>\n",
              "      <td>9.460972</td>\n",
              "      <td>0.358500</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.249100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>8.725600</td>\n",
              "      <td>9.189834</td>\n",
              "      <td>0.356400</td>\n",
              "      <td>0.203000</td>\n",
              "      <td>0.246700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>8.644600</td>\n",
              "      <td>8.918151</td>\n",
              "      <td>0.354300</td>\n",
              "      <td>0.199800</td>\n",
              "      <td>0.243500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>8.215900</td>\n",
              "      <td>8.650140</td>\n",
              "      <td>0.348400</td>\n",
              "      <td>0.194100</td>\n",
              "      <td>0.236900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>8.091700</td>\n",
              "      <td>8.381169</td>\n",
              "      <td>0.345600</td>\n",
              "      <td>0.191700</td>\n",
              "      <td>0.233500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>7.843300</td>\n",
              "      <td>8.163036</td>\n",
              "      <td>0.339300</td>\n",
              "      <td>0.187600</td>\n",
              "      <td>0.228300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>7.691500</td>\n",
              "      <td>7.965528</td>\n",
              "      <td>0.326800</td>\n",
              "      <td>0.180800</td>\n",
              "      <td>0.219800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>7.439900</td>\n",
              "      <td>7.732008</td>\n",
              "      <td>0.327300</td>\n",
              "      <td>0.177400</td>\n",
              "      <td>0.216700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>7.181300</td>\n",
              "      <td>7.511336</td>\n",
              "      <td>0.315900</td>\n",
              "      <td>0.170500</td>\n",
              "      <td>0.207000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "Saving model checkpoint to ./output/checkpoint-48\n",
            "Configuration saved in ./output/checkpoint-48/config.json\n",
            "Model weights saved in ./output/checkpoint-48/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "Saving model checkpoint to ./output/checkpoint-96\n",
            "Configuration saved in ./output/checkpoint-96/config.json\n",
            "Model weights saved in ./output/checkpoint-96/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "Saving model checkpoint to ./output/checkpoint-144\n",
            "Configuration saved in ./output/checkpoint-144/config.json\n",
            "Model weights saved in ./output/checkpoint-144/pytorch_model.bin\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:634: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1408\n",
            "  Batch size = 6\n",
            "Saving model checkpoint to ./output/checkpoint-192\n",
            "Configuration saved in ./output/checkpoint-192/config.json\n",
            "Model weights saved in ./output/checkpoint-192/pytorch_model.bin\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-80f1b3ecf765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1504\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m         )\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1826\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1827\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2094\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOPTIMIZER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2185\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCHEDULER_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:319] . unexpected pos 1641058048 vs 1641057936"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the partially trained model\n",
        "model = EncoderDecoderModel.from_pretrained(\"/content/output/checkpoint-192\").to(device)"
      ],
      "metadata": {
        "id": "utKitw18ja9z",
        "outputId": "31271481-152c-4918-9c54-1f70e5a55069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/output/checkpoint-192/config.json\n",
            "Model config EncoderDecoderConfig {\n",
            "  \"_commit_hash\": null,\n",
            "  \"_name_or_path\": \"/content/model/model/pytorch_model.bin\",\n",
            "  \"architectures\": [\n",
            "    \"EncoderDecoderModel\"\n",
            "  ],\n",
            "  \"decoder\": {\n",
            "    \"_name_or_path\": \"SZTAKI-HLT/hubert-base-cc\",\n",
            "    \"add_cross_attention\": true,\n",
            "    \"architectures\": null,\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": true,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.24.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 32001\n",
            "  },\n",
            "  \"decoder_start_token_id\": 2,\n",
            "  \"encoder\": {\n",
            "    \"_name_or_path\": \"SZTAKI-HLT/hubert-base-cc\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": null,\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"begin_suppress_tokens\": null,\n",
            "    \"bos_token_id\": null,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": null,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"gradient_checkpointing\": false,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-12,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 512,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"bert\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 0,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"suppress_tokens\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tf_legacy_loss\": false,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.24.0\",\n",
            "    \"type_vocab_size\": 2,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 32001\n",
            "  },\n",
            "  \"eos_token_id\": 3,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"model_type\": \"encoder-decoder\",\n",
            "  \"pad_token_id\": 0,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": null,\n",
            "  \"vocab_size\": 32001\n",
            "}\n",
            "\n",
            "loading weights file /content/output/checkpoint-192/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
            "\n",
            "All the weights of EncoderDecoderModel were initialized from the model checkpoint at /content/output/checkpoint-192.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation after further training"
      ],
      "metadata": {
        "id": "5mkn2IREvN2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size)\n",
        "scores = rouge.compute(predictions=results[\"pred_summary\"], references=results[\"Lead\"], rouge_types=[\"rouge1\", \"rouge2\", \"rougeL\"])\n",
        "print(scores['rouge1'].mid)\n",
        "print(scores['rouge2'].mid)\n",
        "print(scores['rougeL'].mid)"
      ],
      "metadata": {
        "id": "OXLs1mJ7vRJJ",
        "outputId": "0df302f7-9f80-4cd8-d725-9bd39933f6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "0b0ecbd6d0834f87a82a93e525531261",
            "d86eee5638024349a342ce56b7ff9657",
            "70252a42d88147159d07b8745193dca6",
            "bfaa8281e5a14d0b84c0e2dc5dc91e4d",
            "b73b79a37e97478bb096b849747f1136",
            "5e328f07d93a4f859182c8b5d9ed9b87",
            "438bbc01a6174a8e94da117b8f773620",
            "cd113ba9f6924b40b11c14253dee833b",
            "6b2cb7a9140944f682ffac5280824429",
            "e66ebf9020d14567acb1ba889205d9a8",
            "0c7c7e63d5974b90aa665efe979df15e"
          ]
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/88 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b0ecbd6d0834f87a82a93e525531261"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score(precision=0.3394126658558153, recall=0.17433156054609722, fmeasure=0.21855974161351402)\n",
            "Score(precision=0.10554923688333667, recall=0.05460701403379933, fmeasure=0.06843854140192641)\n",
            "Score(precision=0.2572409583974006, recall=0.13054149770739543, fmeasure=0.16404860525676673)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save to csv\n",
        "results_df = pd.DataFrame({})\n",
        "results_df['Lead'] = results['Lead']\n",
        "results_df['pred_summary'] = results['pred_summary']\n",
        "results_df['Textbody'] = results['Textbody']\n",
        "results_df.to_excel('results_df.xlsx', index=False)"
      ],
      "metadata": {
        "id": "-nl61rc0XRg6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results_df.iloc[18]['Lead'])\n",
        "print(results_df.iloc[18]['pred_summary'])"
      ],
      "metadata": {
        "id": "4CTynI71bmtj",
        "outputId": "379db543-04b6-473e-8515-55742480d3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Újra kell tárgyalni a költségvetési csalás miatt elítélt pécsváradi polgármester ügyét. Erről kedden döntött a Pécsi Ítélőtábla.\n",
            "Z Z Zádori János szerint az ügy nem egy nagy ügy, hanem egy nagy ügy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1WynWfzugSU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}